{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from src.preprocess import preprocessing_fn_dict\n",
    "from src.helper import *\n",
    "\n",
    "config = parse_config('/Users/rayandaod/Documents/Docs/Job Search/ILLUIN/intent_classification/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder_name = 'CLINC150_oos1_down_carry_trans_sentenceCamembertBase'\n",
    "dataset_version = 'plus'\n",
    "data_keywords = '_'.join(dataset_folder_name.split('_')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(os.path.join('../data', dataset_folder_name, dataset_version, 'train', f'train_{data_keywords}.pkl'))\n",
    "val_df = pd.read_pickle(os.path.join('../data', dataset_folder_name, dataset_version, 'validation', f'validation_{data_keywords}.pkl'))\n",
    "test_df = pd.read_pickle(os.path.join('../data', dataset_folder_name, dataset_version, 'test', f'test_{data_keywords}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedding and convert them to numpy arrays\n",
    "X = train_df['embedding']\n",
    "\n",
    "# Get the labels\n",
    "y = train_df['label']\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Print the labels and their encoded values as a dictionary\n",
    "# dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "X = np.array(X.tolist())\n",
    "\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Initialize PCA and the X vector for dimensionality reduction\n",
    "# pca = PCA(n_components=0.95)  # keep 95% of variance\n",
    "# pca.fit(X)  # X_train is your training data\n",
    "\n",
    "# # Step 2: Apply dimensionality reduction to X\n",
    "# X = pca.transform(X)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'logReg'\n",
    "\n",
    "if model_type == 'logReg':\n",
    "    classifier = LogisticRegression(random_state=config['random_state'], max_iter=1000)\n",
    "\n",
    "elif model_type == 'xgb':\n",
    "    classifier = XGBClassifier(random_state=config['random_state'], max_depth=10, n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "elif model_type == 'decisionTree':\n",
    "    classifier = DecisionTreeClassifier(random_state=config['random_state'])\n",
    "\n",
    "elif model_type == 'randomForest':\n",
    "    classifier = RandomForestClassifier(random_state=config['random_state'])\n",
    "\n",
    "elif model_type == 'gradientBoost':\n",
    "    classifier = GradientBoostingClassifier(random_state=config['random_state'])\n",
    "\n",
    "elif model_type == 'adaBoost':\n",
    "    classifier = AdaBoostClassifier(random_state=config['random_state'])\n",
    "\n",
    "elif model_type == 'mlp':\n",
    "    classifier = MLPClassifier(random_state=config['random_state'], max_iter=1000)\n",
    "\n",
    "# Fit the model in a cross validation fashion\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(classifier:object, df:pd.DataFrame, title:str) -> pd.DataFrame:\n",
    "    \"\"\"Evaluate a classifier on a dataframe.\n",
    "\n",
    "    Args:\n",
    "        classifier (object): The classifier to evaluate.\n",
    "        df (pd.DataFrame): The dataframe to evaluate the classfiier on.\n",
    "        title (str): The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with the predicted classes.\n",
    "    \"\"\"\n",
    "    # Copy the dataframe\n",
    "    df = df.copy()\n",
    "\n",
    "    # Encode the labels\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # If the column 'embedding' does not exist, we should run the preprocessing functions\n",
    "    if 'embedding' not in df.columns:\n",
    "        for preprocessing_fn_name in config['training_inference_data_prep']:\n",
    "            df = preprocessing_fn_dict[preprocessing_fn_name][0](df, verbose=config['verbose'])\n",
    "\n",
    "    # Get the embeddings\n",
    "    X_eval = np.array(df['embedding'].tolist())\n",
    "\n",
    "    # Apply PCA\n",
    "    # X_eval = pca.transform(X_eval)\n",
    "\n",
    "    # Get the labels and encode them\n",
    "    y_eval = encoder.fit_transform(df['label'])\n",
    "\n",
    "    # Predict\n",
    "    y_pred = classifier.predict(X_eval)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    accuracy_score(y_eval, y_pred)\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    conf_mat = confusion_matrix(y_eval, y_pred)\n",
    "    conf_mat_df = pd.DataFrame(conf_mat, index = encoder.classes_, columns = encoder.classes_)\n",
    "    conf_mat_df.index.name = 'Actual'\n",
    "    conf_mat_df.columns.name = 'Predicted'\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize = (20, 14))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the classification report\n",
    "    print(classification_report(y_eval, y_pred, target_names=encoder.classes_))\n",
    "\n",
    "    # Add the predicted classes to the dataframe\n",
    "    df['predictions'] = encoder.inverse_transform(y_pred)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the training set\n",
    "train_df_new = evaluate_model(classifier, train_df, 'Training')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_df_new = evaluate_model(classifier, val_df, 'Validation')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_df_new = evaluate_model(classifier, test_df, 'Test')\n",
    "\n",
    "# Evaluate the model on the example set\n",
    "example_df = pd.read_csv(os.path.join('..', config['example_set_local_path']))\n",
    "example_df_new = evaluate_model(classifier, example_df, 'Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier and the label encoder\n",
    "model_folder_name = model_type + '_on_' + dataset_folder_name.split('_')[0] + dataset_version + '_' + dataset_folder_name.split('_')[1:]\n",
    "model_path = f'../models/{model_folder_name}'\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "pickle.dump(classifier, open(f'{model_path}/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "illuin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
