{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "RANDOM_STATE = 42  # For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/CLINC150_oos1_down_carry_trans_stop_flaubert_average_norm/small'\n",
    "\n",
    "train_df = pd.\n",
    "val_df = pd.read_csv('../data/clinc150_validation_down_tr_emb.csv', converters={'embeddings_avg': eval})\n",
    "test_df = pd.read_csv('../data/clinc150_test_down_tr_emb.csv', converters={'embeddings_avg': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedding and convert them to numpy arrays\n",
    "X = np.array(train_df['embeddings_avg'].tolist())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels\n",
    "y = train_df.filter(regex='label')\n",
    "display(y)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "print(y)\n",
    "\n",
    "# Print the labels and their encoded values as a dictionary\n",
    "dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'log_reg'\n",
    "\n",
    "if model_type == 'log_reg':\n",
    "    classifier = LogisticRegression(C=1.0, penalty='l2', random_state=RANDOM_STATE, max_iter=1000)\n",
    "\n",
    "elif model_type == 'xgb':\n",
    "    classifier = XGBClassifier(random_state=RANDOM_STATE, max_depth=10, n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "elif model_type == 'decision_tree':\n",
    "    classifier = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "elif model_type == 'random_forest':\n",
    "    classifier = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "elif model_type == 'gradient_boost':\n",
    "    classifier = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "elif model_type == 'ada_boost':\n",
    "    classifier = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "elif model_type == 'mlp':\n",
    "    classifier = MLPClassifier(random_state=RANDOM_STATE, max_iter=1000)\n",
    "\n",
    "# Fit the model in a cross validation fashion\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the training set\n",
    "train_df_new = evaluate_model(classifier, train_df, 'Training')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_df_new = evaluate_model(classifier, val_df, 'Validation')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_df_new = evaluate_model(classifier, test_df, 'Test')\n",
    "\n",
    "# Evaluate the model on the example set\n",
    "example_df = pd.read_csv('../data/examples.csv')\n",
    "example_df_new = evaluate_model(classifier, example_df, 'Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier and the label encoder\n",
    "pickle.dump(classifier, open(f'../models/{model_type}_classifier.pkl', 'wb'))\n",
    "pickle.dump(label_encoder, open(f'../models/label_encoder.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier\n",
    "classifier = pickle.load(open(f'../models/{model_type}_classifier.pkl', 'rb'))\n",
    "\n",
    "# Get the embeddings\n",
    "X_eval = train_df.filter(regex='embeddings_avg')\n",
    "\n",
    "# Convert the embeddings to numpy arrays\n",
    "X_eval = np.array(X_eval['embeddings_avg'].tolist())\n",
    "print(X_eval.shape)\n",
    "\n",
    "# Predict\n",
    "y_pred = classifier.predict(X_eval)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas display options to make rows larger\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "val_df_new[val_df.label == 'travel_suggestion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "illuin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
